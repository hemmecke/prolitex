\documentclass[a4paper]{article} % 2>/dev/null || <<'%%%%% BUILD-SCRIPT'

% The above line together with everything in this file that follows
% the end of the HERE-DOC will be executed via "sh prolitex.awk.tex".

\usepackage{prolitex}
\usepackage[x11names]{xcolor}
\lstset{backgroundcolor=\color{SlateBlue3!10!gray!10!white},
  captionstyle=\bfseries\color{SlateBlue4},
  language=Awk}
%\usepackage{url}
\usepackage{hyperref}

\newcommand{\packagename}[1]{{\normalfont\sffamily#1}}
\newcommand\ProLiteX{\textsf{ProLiteX}}
\newcommand\prolitex{\packagename{prolitex}}
\newcommand{\ie}{i.\,e.}
\lstnewenvironment{myverbatim}%
  {\lstset{basicstyle=\scriptsize\ttfamily,gobble=2,language={}}}%
  {}
% We must use basicstyle=\scriptsize in order to get about 80
% charactes per line in the code chunk.
\lstset{basicstyle=\scriptsize}

% Similar to the definition of the description environment in
% article.cls.
\newenvironment{ttdescription}
  {\list{}{\labelwidth0pt \itemindent-\leftmargin
      \def\makelabel##1{\hspace\labelsep
        \normalfont\ttfamily ##1:}}}
  {\endlist}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
% Because we use << inside a chunk (for example to specify
% bdelimglobal), we must redefine the default chunkref delimiter.
% Since this file does actually use chunkref delimiters, it does not
% matter to what delimiters we redefine the default. It just should
% not appear inside any of the following chunk or myverbatim
% environments.
\lstset{chunkref={@<@}{@>@}}

\title{\ProLiteX}
\date{06-Jun-2010}
\author{Ralf Hemmecke}
\maketitle

\begin{abstract}
  The \ProLiteX{} project consists of a collection of tools to
  supports literate programming. In contrast to most other tools
  \ProLiteX{} has no weave command to extract a \texttt{.tex} document
  from the literate sources. Instead, \ProLiteX{} defines an ordinary
  \LaTeX{} \texttt{chunk} environment into which program code is to be
  written. Due to that, literate sources are pure \LaTeX{} files.

  As the tangle part, \ie, extracting the source code from the
  literate sources, \ProLiteX{} provides an \packagename{awk} script.
\end{abstract}
\tableofcontents

\section{User's Guide}

A literate document which is suitable for \ProLiteX{} is an ordinary
\LaTeX{} document that has a number of \texttt{chunk} environments in
it. A simple document (let's call it \texttt{file.tex}) might look
like this.
\begin{myverbatim}
  \documentclass[a4paper]{article}
  \usepackage{prolitex}
  \begin{document}
  \begin{chunk}{CHUNKNAME A}
  for a in 1..9 repeat {
    <<CHUNKNAME B>>
  }
  \end{chunk}
  \begin{chunk}{CHUNKNAME C}
  code from chunk C
  \end{chunk}
  \begin{chunk}{CHUNKNAME B}
  some code from chunk B
      <<CHUNKNAME C>>
  more code from chunk B
  \end{chunk}
  \end{document}
\end{myverbatim}
After running the 
\texttt{tangle} program via
\begin{myverbatim}
  ./prolitex file.tex
\end{myverbatim}
on the above file one should get the following output.
\begin{myverbatim}
  for a in 1..9 repeat {
    some code from chunk B
        code from chunk C
    more code from chunk B
  }
\end{myverbatim}
Note in particular the indentation of the code.

The script \texttt{prolitex} is nothing else than a one-line shell
script with the following contents.
\begin{myverbatim}
  awk -f prolitex.awk -- "$@"
\end{myverbatim}
That script is usually generated when the \ProLiteX{} package is
compiled.

In the following we describe the \ProLiteX{} version of a
\texttt{tangle} program written in \packagename{awk}.
%
The \prolitex{} script accepts several command line options that will
be described below. Usually, the script will be called by giving a
\texttt{-R} command line option. However, if no option is given, the
script figures out all the top-level chunks, \ie, the chunks that are
not included by any other chunk, and expands and outputs all of them
(in no particular order).

In contrast to \packagename{noweb} \ProLiteX{} has no default root
chunk name. If a file contains exactly one top-level chunk (of any
name) then calling \prolitex{} without \texttt{-R} might be the
preferred way to call \prolitex{}.

\begin{ttdescription}
\item[-R \texttt{name}] Expand and output the chunk \texttt{name} to
  stdout. Several \texttt{-R} options can be given with the meaning
  that the corresponding expanded chunks are written to stdout one
  after the other.

  If no \texttt{-R} option is given, then all root chunks are expanded
  and output in no particular order.

\item[-L \texttt{format}] Write a line number indication at the
  beginning of each chunk. For example for the C programming language
  one would specify the following.
  \begin{myverbatim}
  -L '#line %L "%F"%N'
  \end{myverbatim}

  The following placeholders can be used:
  \begin{ttdescription}
  \item[\%L]  Expands to the repective line number.
  \item[\%F]  Expands to the current file name.
  \item[\%N]  Expands to a newline.
  \item[\%\%] Expands to a percent sign.
  \end{ttdescription}

  When an explicit \texttt{-L} option is given, indentation of
  sub-chunks is switched off, \ie, column number of characters in
  input and output agree. This is appropriate, since some compilers
  also indicate the column number on compile time error and thus it is
  easier to locate the error directly in the literate source.

  If \prolitex{} is called via
  \begin{myverbatim}
  ./prolitex -L '#line %L "%F"%N' file.tex
  \end{myverbatim}
  the output will look as follows.
  \begin{myverbatim}
  #line 5 "file.tex"
  for a in 1..9 repeat {
    
  #line 13 "file.tex"
  some code from chunk B
      
  #line 10 "file.tex"
  code from chunk C
  #line 14 "file.tex"
  
  more code from chunk B
  #line 6 "file.tex"
  
  }
  \end{myverbatim}

\item[-a] Output all chunk names defined in the input file.

\item[-r] Output all chunk root names, \ie, definitions of chunks that
  are nowhere used.

\item[--version] Print the version number and do not process the file.
\end{ttdescription}

If \texttt{--version} is given on the command line, all other options
are irrelevant. The option \texttt{-a} takes precedence over all
remaining options. If \texttt{-r} is given, the options \texttt{-L}
and \texttt{-R} are ignored.

Since tabs are not translated into spaces, one has to be careful with
proper indentation. If one line uses tabs and another one uses spaces,
then indentation of included chunks might appear wrong.



\section{Implementation}

Since this file is a literate program (\ie, it contains documentation
and source code) of \ProLiteX's tangle command, there is a little
bootstrapping problem. \ProLiteX's tangle program cannot yet be
assumed to exist. We, therefore, do not use code junk references here
and write the program in a linear fashion so that just extracting the
lines inbetween \verb|\begin{chunk}| and \verb|\end{chunk}| will give
the respective source code.

This extraction can easily be done by piping this file through the
following simple \packagename{awk} command.
\begin{myverbatim}
  awk '/^\\begin{chunk}/{c=1;next};/^\\end{chunk}/{c=0;next};c'
\end{myverbatim}

Since this \packagename{awk} file should be a script, we start with an
appropriate first line. Note that we assume that the executable
\texttt{awk} lives under \texttt{/usr/bin}. That might not everywhere
be the case. Maybe our \texttt{configure} script should deal with
this issue.
\begin{chunk}{*}
#!/usr/bin/awk -f
\end{chunk}

Let's have an error function that aborts the program.
\begin{chunk}{*}
function error(msg) {
  print "==========================================="
  print "Error in line " NR " of " FILENAME "."
  print msg
  exit 1
}
\end{chunk}

\subsection{Command Line Options}

Since our set of command line options is rather limited, we parse the
options ourselves. Options parsing stops, if eigther a double dash or
a non-known option is seen on the command line.
\begin{chunk}{*}
function getopt(  i, r) {
  i = 1; r = 0
  while (i < ARGC && ARGV[i] != "--") {
    a = ARGV[i]; ARGV[i]=""
    if      (a == "--version") {optversion = 1; exit 0}
    else if (a == "-a") {optallchunknames = 1}
    else if (a == "-r") {optallrootnames  = 1}
    else if (a == "-R") {i++; roots[r] = ARGV[i]; ARGV[i]=""; r++}
    else if (a == "-L") {i++; linedirectiveformat = ARGV[i]; ARGV[i]=""}
    else {ARGV[i] = a; break}
    i++
  }
}
BEGIN {getopt()}
\end{chunk}

For the \texttt{-L} option we need a procedure that replaces the
templates by the respective data. The parameters $L$ and $F$ are
inserted into the format and produce the respective line directive.
\begin{chunk}{*}
function linedirective(L, F,  idx, indent, fmt, c, ld) {
  if (linedirectiveformat == "") {return ""}
  fmt = linedirectiveformat
  ld = ""
  while ((idx = index(fmt, "%")) && (idx != length(fmt))) {
    ld = ld substr(fmt, 1, idx-1)
    c = substr(fmt,idx+1,1)
    if      (c == "L") {ld = ld L}
    else if (c == "F") {ld = ld F}
    else if (c == "N") {ld = ld "\n"}
    else if (c == "%") {ld = ld "%"}
    else {ld = ld "%" c}
    fmt = substr(fmt, idx+2)
  }
  return ld fmt
}
\end{chunk}


\subsection{The Tangle Process}

The implementation is done for two cases (a) where the chunkref
delimiters do not change and (b) where they can change due to a
\verb'\lstset' command or optional parameters in square brackets
immediately after \verb%\begin{cunk}%.

Since parsing the input to find out when the \texttt{chunkref}
delimiters change in case (b) is quite a bit more complicated than the
default case (a), we decided to first describe case (a) in
Sections~\ref{sec:phase1} and \ref{sec:phase2}. Parsing for new
chunkref delimiters is treated in Section~\ref{sec:parsing}.

The flow of the \packagename{awk} program is simple and done in three
phases.

\begin{enumerate}
\item First, we collect all chunk data in an array \texttt{data}. Each
  chunk environment from the source file becomes a separate entry. No
  concatenation of chunks is done. And no chunk references are
  resolved.

\item The first phase ends when the \texttt{END} clause of the
  \packagename{awk} program will be executed, \ie, when the whole
  source file has been read.
%
  The second phase expands the chunks and determines which chunks are
  root chunks.

\item Finally, in the third phase, the desired data is written to stdout
  or to the respective files.
\end{enumerate}
\subsection{Phase 1}\label{sec:phase1}
\subsubsection{Globabl Variables in Phase 1}

We basically store all the information about the chunks in an array
\texttt{data}. Additionally, each unique chunkname is collected as an
index in the array \texttt{chunk}.

We list here the all the global variables.
\begin{ttdescription}
\item[bdelimglobal \textrm{and} edelimglobal] These variables are used
  to store the global settings for the chunkref delimiters.
\begin{chunk}{*}
BEGIN {
  bdelimglobal = "<<"
  edelimglobal = ">>"
}
\end{chunk}
If no other delimiters are given, these will be used. 
By a command of the form
\begin{myverbatim}
  \lstset{chunkref={<[}{]>}}
\end{myverbatim}
the global chunkref delimiters can be changed for the following chunk
enviroments to \texttt{<[} and \texttt{]>}.
\begin{chunk}{*}
/^\\lstset{/ {
  lineidx = 8 # start parsing after "\lstset{"
  if (parseoptions() != "}") {error("Expected closing brace")}#$
  if (setchunkref()) {bdelimglobal = bdelim; edelimglobal = edelim}
  next
}
\end{chunk}
In the above chunk, since we stop processing via the \texttt{next}
statement, we ignore everything that comes after the closing brace on
the same line. The functions \texttt{parseoptions} and
\texttt{setchunkref} are defined in Section~\ref{sec:parsing}.

\item[data] Input lines between
\begin{myverbatim}
  \begin{chunk}{chunkname}
\end{myverbatim}
and 
\begin{myverbatim}
  \end{chunk}
\end{myverbatim}
are collected into the array \texttt{data}.%
\footnote{In general, there can be an optional argument enclosed in
  square brackets between \texttt{\{chunk\}} and
  \texttt{\{chunkname\}}.}
%
Note that both of the environment delimiters are supposed to start at
the beginning of the line.

A detailed description follows below.

\item[inchunk] This variable is true if we are inside a chunk, \ie, if
  we must collect the lines.

\item[chunkname] The name of the current chunk.

\item[part] The part number of the current chunk. The smallest number
  is 1.

\item[lines] Not really necessary, but is used to collect all chunk
  lines before they are stored into
  \texttt{data[chunkname,part,"lines"]}.

\item[chunkref] Not really necessary, but is used to remember whether
  there is a chunk reference inside the current chunk. At the end of
  the current chunk part, its value is stored into
  \texttt{data[chunkname,part,"chunkref?"]}.
%
  A non-zero value indicates that this chunk contains an unexpanded
  chunk reference.
\end{ttdescription}
There are more global variables, but since they are all connected to
the parsing of the \verb'\lstset' argument or the optional argument of
\verb'\'\verb'begin{chunk}', we rather describe them in
Section~\ref{sec:parsing}.


\subsubsection{The \texttt{data} Array}
Let us describe the contents of the array \texttt{data} in more
detail.

Since there might be different chunks with the same name and we plan
for changes of the chunkref delimiters, we define for each
\texttt{chunkname} the following array indices, where
\texttt{chunkname} and \texttt{part} have the meaning from above.

\begin{ttdescription}
\item[chunkname,"parts"] The number of chunks with the same name.

\item[chunkname,part,"lineno"] The source line number of the first
  chunk line. This will be used to generate \texttt{\#line}
  directives.

\item[chunkname,part,"filename"] The source filename where the chunk
  lives. This will be used to generate \texttt{\#line} directives.

\item[chunkname,part,"lines"] The content of a part of a chunk. All
  lines are concatenated and stored in this entry. The trailing
  newline character of the last line is removed.

\item[chunkname,part,"bdelim"] The starting chunkref delimiter
  sequence that is valid for this chunk.

\item[chunkname,part,"edelim"] The ending chunkref delimiter sequence
  that is valid for this chunk.

\item[chunkname,part,"chunkref?"] This is true (\ie, greater than 0)
  if in this part of the chunk there are references to other chunks.
\end{ttdescription}

\subsubsection{Code for Phase 1}

We start with a first simple implementation where we do not consider
any options that change the default setting for the chunkref
delimiters, which are \texttt{<<} and \texttt{>>}.

Let's first treat the simple case to start a chunk, \ie, the chunk has
no optional parameter. We don't allow any character appearing after
the closing brace that ends the chunkname.
\begin{chunk}{*}
/^\\begin{chunk}{.+}$/ {#$
  chunkname = substr($0,15,length($0)-15)
  enterchunk(chunkname, bdelimglobal, edelimglobal)
  next
}
\end{chunk}

Entering a chunk simply initializes certain variables. We have put
this code into a separate function because it can be reused for
entering a chunk that has an optional parameter.
\begin{chunk}{*}
function enterchunk(chunkname, bdelim, edelim) {
  inchunk = 1
  part = ++data[chunkname,"parts"]
  if (part == 1) {chunk[chunkname] = 0} # assume that this is a root chunk
  data[chunkname,part,"bdelim"] = bdelim
  data[chunkname,part,"edelim"] = edelim
  data[chunkname,part,"lineno"] = NR+1
  data[chunkname,part,"filename"] = FILENAME
  lines = ""
  chunkref = 0 #no chunkref found so far
}
\end{chunk}

If a chunk environment is immediately followed by an open bracket, we
first parse the optional parameter and then assume that the rest of
the line is the chunkname enclosed in braces. We do not allow any
character after the closing brace, not even white space.
The optional parameter can span several lines, though.

The function \texttt{parseoptions} leaves the variable
\texttt{lineidx} pointing to the next character in the current input
line. It should be the start of the \verb"{CHUNKNAME}".

The function \texttt{setchunkref} then takes the \texttt{options}
array and determines the values of the begin and ending delimiter.

Both \texttt{parseoptions} and \texttt{setchunkref} are described in Section~\ref{sec:parsing}
\begin{chunk}{*}
/^\\begin{chunk}\[/ {
  lineidx = 14 # start parsing after "\begin{chunk}["
  if (parseoptions() != "]") {error("Expected closing bracket")}
  chunkname = substr($0,lineidx+1,length($0)-lineidx-1)
  if (substr($0, lineidx, 1) != "{" || substr($0, length($0), 1) != "}") {#$
    error("Chunkname (" chunkname ") not enclosed in braces.")
  }
  setchunkref()
  enterchunk(chunkname, bdelim, edelim)
  next
}
\end{chunk}

Eventually, we switch off the chunk treatment. It only makes sense if
we are inside a chunk. Otherwise we abort.
\begin{chunk}{*}
/^\\end{chunk}/ {
  if (inchunk == 0) {
    error("Have found \\end{chunk} without \\begin{chunk}.")
  }
  data[chunkname,part,"lines"] = substr(lines,2) # remove initial \n
  data[chunkname,part,"chunkref?"] = chunkref
  data[chunkname,"chunkref?"] += chunkref
  inchunk=0
  next
}
\end{chunk}

It is also easy to actually treat the chunk, \ie, when we are inside a
chunk and read the chunk lines. Note that this chunk must come after
the part that treats the end of a code chunk. If it came before that
chunk then \verb'\'\verb'end{chunk}' would be considered as part of
the chunk.
\begin{chunk}{*}
inchunk {
  chunkref += index($0, data[chunkname,part,"bdelim"]) #$
  lines = lines "\n" $0 #$
  next
}
\end{chunk}


\subsection{Phase 2}\label{sec:phase2}
\subsubsection{Globabl Variables in Phase 2}

In addition to the indices of the \texttt{data} array given above, the
following indices are used.
%
Phase 2 will only read the values from the indices in Phase 1, but
never change them.
\begin{ttdescription}
\item[chunkname,"lines"] The whole chunk, \ie, all parts concatenated
  and properly expanded. This is only defined if there is an already
  computed expanded chunk.
\end{ttdescription}

Since \packagename{awk} does not allow to return objects, we use
global variables. The following global variables are set by the
function \texttt{haschunkref} as a side effect and are not modified by
any other function.
\begin{ttdescription}
\item[before] to the string part before matching \texttt{bdelim},
\item[chunkrefname] to the name that has been found,
\item[after] to the string part after the closing \texttt{edelim},
\end{ttdescription}


\subsubsection{Code for Phase 2}

Let us define some auxiliary functions.

The following function \texttt{haschunkref} returns the index where a
chunk reference has been found. It is the first index of the string
\texttt{bdelim}. If no chunk reference can be found this function
returns 0.

As a side effect, this function sets the global variables
\texttt{before}, \texttt{chunkrefname}, \texttt{after}. See their
description above.

\begin{chunk}{*}
function haschunkref(s, bdelim, edelim,   b, c, e) {
  b = index(s, bdelim)
  if (b == 0) { return 0 }
  before = substr(s, 1, b-1)
  c = b + length(bdelim)
  e = index(substr(s, c), edelim)
  if (e == 0) {
    error("Closing chunkref delimiter not found.")
  }
  chunkrefname = substr(s, c, e-1)
  after = substr(s, c+e+length(edelim)-1)
  return b
}
\end{chunk}

Including chunk in one line \texttt{aline} means to determine the
index and name of the chunk reference and replace it by the
corresponding (properly indented) code chunk. The chunk delimiters
have to be given when the function is invoked.
\begin{chunk}{*}
function includechunks(aline, bdelim, edelim, ld,
  # local variables
  indent, moreindent, lines, s) {
  indent = ""
  while (haschunkref(aline, bdelim, edelim)) {
    if (!(chunkrefname in chunk)) {
      error("chunk name '" chunkrefname "' not defined")
    }
    aline = after # what's next
    chunk[chunkrefname] = 1 # chunkrefname is used, i.e. no root chunk
    lines = data[chunkrefname,"lines"]
    if (linedirectiveformat) {
      s = s indent before "\n" lines
      if (aline) {s = s "\n" ld}
      moreindent = before bdelim chunkrefname edelim
      gsub(/[^\t]/, " ", moreindent)
      indent = indent moreindent
      continue
    }
    # Compute indent amount for the chunk to include ...
    moreindent = before; gsub(/[^\t]/, " ", moreindent)
    indent = indent moreindent
    # ... and indent accordingly.
    gsub(/\n/, "\n" indent, lines)
    s = s before lines
    # There is more indentation for the next potential chunk.
    moreindent = bdelim chunkrefname edelim; gsub(/[^\t]/, " ", moreindent)
    indent = indent moreindent
  }
  return s aline
}
\end{chunk}

When we enter Phase 2, no chunk has yet been expanded. Since one chunk
may comprise several parts that have to be expanded separately and
then concatenated, we have two functions that mutually call each
other. While \texttt{expandchunkrefsN} recursively expands the chunk
references of a chunk part with name \texttt{chunkname} and number
\texttt{part}, the function \texttt{expandchunkrefs} expands all chunk
parts, concatenates them and stores these lines into the variable
\texttt{data[chunkname,"lines"]}.

\begin{quote}
  \textbf{Warning:} There is no code that detects recursion in the
    chunks. The chunk structure is supposed to form a tree (or rather
    a forest, since there might be several roots).
\end{quote}

Due to passing arrays by reference in \packagename{awk}, we basically
cannot use arrays in recursive invocations of functions. Therefore, we
parse the given chunk lines twice. In the first round, we do not yet
compute the resulting lines, but rather only recursively expand the
chunks that are referenced from the current chunk. In the second round
we can simply include the (already) expanded lines from the referenced
chunks.
\begin{chunk}{*}
function expandchunkrefsN(chunkname,part,
  # local variables
  chunkdata, bdelim, edelim, n, s, i, line, lineno, filename, ld) {
  #
  chunkdata = data[chunkname, part, "lines"]
  lineno    = data[chunkname, part, "lineno"]
  filename  = data[chunkname, part, "filename"]
  ld = linedirective(lineno,filename)
  # return early if the chunk does not reference other chunks
  if (data[chunkname, part, "chunkref?"] == 0) {return ld chunkdata}
  # First round.
  bdelim = data[chunkname, part, "bdelim"]
  edelim = data[chunkname, part, "edelim"]
  while (haschunkref(chunkdata, bdelim, edelim)) {
    chunkdata = after
    expandchunkrefs(chunkrefname)
  }
  # Second round. Now every subchunk is properly expanded. We include them.
  n = split(data[chunkname,part,"lines"],line,"\n")
  if (n == 0) {return ""} # empty chunk
  s = ld includechunks(line[1], bdelim, edelim, ld)
  for(i=1; i<n; i++) {
    s = s "\n"
    ld = linedirective(lineno+i, filename)
    if (haschunkref(line[i], bdelim, edelim)) {s = s ld}
    s = s includechunks(line[i+1], bdelim, edelim, ld)
  }
  return s
}
\end{chunk}

And now we expand the various chunk parts and store these lines
concatenated into \texttt{data[chunkname,"lines"]}.
\begin{chunk}{*}
function expandchunkrefs(chunkname,   parts, s, k) {
  # return early if the chunk has already been expanded
  if ((chunkname,"lines") in chunk) { return data[chunkname,"lines"] }
  parts = data[chunkname,"parts"]
  s = expandchunkrefsN(chunkname,1)
  for (k=2; k<=parts; k++) {s = s "\n" expandchunkrefsN(chunkname,k)}
  data[chunkname,"lines"] = s
  return s
}
\end{chunk}



\subsection{Phase 3}\label{sec:phase3}
The following piece of code is always executed. It trigges the output
according to the given command line options.

\begin{chunk}{*}
END {
  if (optversion) {
    print "ProLiteX 0.1"
    print "Copyright (C) 2010,  Ralf Hemmecke <ralf@hemmecke.de>"
  } else if (optallchunknames) { # print all chunk names
    for (i in chunk) {print i}
  } else if (optallrootnames) { # print root names
    for (i in chunk) {expandchunkrefs(i)}
    for (i in chunk) {if (chunk[i]==0) {print i}}
  } else { # expand the chunks
    r = length(roots)
    # No -R has been given, so expand all root chunks.
    for (i in chunk) {expandchunkrefs(i)}
    if (r == 0) {for (i in chunk) {if (chunk[i]==0) {roots[r] = i; r++}}}
    for (i=0; i<r; i++) {
      if (roots[i] in chunk) {print expandchunkrefs(roots[i])}
      else {error("There is no chunk with name '" roots[i] "'.")}
    }
  }
}
\end{chunk}



\subsection{The Options Parsing}\label{sec:parsing}
In general the \packagename{listings} package allows to control the
\texttt{lstlisting} environment. This is inherited by \ProLiteX{},
\ie, one can pass options to a \texttt{chunk} environment in two ways.
\begin{enumerate}
\item Using the \verb'\lstset' command. These options take global
  effect. Example:
\begin{myverbatim}
  \lstset{chunkref={<'}{'>},gobble=2}
\end{myverbatim}
\item Writing options into the optional part of the \texttt{chunk}
  environment. They only affect the chunk locally. Example:
\begin{myverbatim}
  \begin{chunk}[chunkref={<'}{'>},gobble=2]{CHUNKNAME}
    code goes here
  \end{chunk}
\end{myverbatim}
\end{enumerate}


\subsubsection{The Options Regular Expression}
Options form a comma separated list of \texttt{key=value} pairs where
the \texttt{key} is an ordinary word just consisting of letters and
\texttt{value} is an expression that may contain braces only in a
properly nested and balanced fashion.

In a \verb'\lstset' argument occuring brackets at top level
must be balanced. Furthermore, special \TeX{} characters like
\begin{myverbatim}
  \ { } $ & # ^ _ % ~
\end{myverbatim}
%$
must be escaped by a backslash.

In order to parse the options we assume the following grammar (in
EBNF):
\begin{lstlisting}[keywords={comma, equal, word, cs, obrace, cbrace,
    obracket, cbracket}, label=grammar]
options   ::= keyval { comma keyval }
keyval    ::= [ key [ equal value ] ]
key       ::= word
value     ::= { balanced }
balanced  ::= balancedx | obracket balancedx cbracket
balancedx ::= { word | cs | obrace  balancedz cbrace }
balancedz ::= { comma | equal | obracket | cbracket | balancedx }
\end{lstlisting}
The bold faced symbols are returned by the lexer. They are defined as
follows.
\begin{lstlisting}[string={[d]"},stringstyle=\ttfamily]
comma    ::= ","
equal    ::= "="
obrace   ::= "{"
cbrace   ::= "}"
obracket ::= "["
cbracket ::= "]"
cs       ::= "\" letter { letter }
word     ::= { diglet | special | other }
letter   ::= "a"|...|"z" | "A"|...|"Z"
diglet   ::= "0"|...|"9" | letter
special  ::= "\\" | "\{" | "\}" | "\$" | "\&" | "\#" | "\^" | "\_"
           | "\%" | "\~"
other    ::= "@" | "!" | "|" | "'" | "(" | ")" | "*" | "+" | "-" | "."
           | "/" | ":" | ";" | "=" | "<" | ">" | "?" | """
\end{lstlisting}
This grammar is a very simplified form of what is actually allowed.
For example, it completely ignores white space in keyword values.
Since we are only interested in the value of \texttt{chunkref} and in
finding the end of the key/value pairs, ignoring white space is not an
issue.

The grammar also accepts keywords that consist of non-letters. This is
wrong, but our tangle script is not responsible for checking the
correctness of the \LaTeX{} text and the only keyword that is of
interest to us, is \texttt{chunkref}.

The lexer considers tabulators, spaces and newlines as white space.
White space also separates tokens. The lexer removes \LaTeX{} comments
from the input.

Special characters can be returned as word constituents by the lexer.
They will appear with the backslash removed.

The basic ideas for the following parser can be found in
\cite[pp.~9--20]{Wirth:2005}. Our parser is not very sophisticated. In
addition to recognizing the key/value structure, we collect all the
key/value pairs in a global array \texttt{options}.

\subsubsection{Global Variables for Lexer and Parser}

Since \packagename{awk} does not have constants, we give here two
variables that are actually used as constants. According to the
grammar letters can be used as part of a control sequence. Non-word
characters are used to recognize the end of a word.
\begin{chunk}{*}
BEGIN {
  letter      = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
  nonwordchar = " %,={}[]\\"
}
\end{chunk}

The other global variables are given as follows.
\begin{ttdescription}
\item[ch] The next (look-ahead) character that is set by the function
  \texttt{nextCharacter}.

\item[sym] Holds the next (look-ahead) token that is set by the
  function \texttt{getsym}.

\item[symvalue] For word and control sequence tokens this variable
  holds the corresponding word or control sequence.

\item[lineidx] The character \texttt{ch} is given by the reading from
  the current input line at index \texttt{lineidx}.

\item[kvalue] Holds the value for the current keyword. Its value is
  accumulated during parsing and returned by the function
  \texttt{gvalue}.

\item[options] Holds all the keyword/value pairs that are recognized
  during parsing an \verb'\'\verb'lstset' or optional
  \verb'\'\verb'begin{chunk}' argument.

\end{ttdescription}


\subsubsection{The Lexer}
The lexer is a function that returns the next token. Tokens are given
by the bold face symbols above.

Since the above grammar is so simple, we do not introduce particular
tokens but rather use the characters directly in the meaning of
tokens. For the tokens \texttt{cs} and \texttt{word} we reserve the
characters \texttt{"c"} and \texttt{"w"}, respectively.

Let us first implement a function \texttt{nextCharacter} which returns
the next character from the input stream and stores it in the global
variable \texttt{ch}. That function will already transform tabulators and
newlines into a space.

\begin{chunk}{*}
function nextCharacter() {
  lineidx += 1
  if (lineidx <= length($0)) {
    ch = substr($0, lineidx, 1)#$
  } else {
    if (getline <= 0) {error("Unexpected end of file.")}
    lineidx = 0
    ch = " " # new line
  }
  if (ch == "\t") { ch = " " }
}
\end{chunk}

The function \texttt{getsym} decides upon the look-ahead character
\texttt{ch} which token is to be returned. If the token consists of
several characters, \ie, if it is a word or control sequence token, it
will read the respective amount of characters from the input stream.
The variable \texttt{ch} will then contain the next character after
the word or control sequence token.

Since we have a simple grammar, except for the tokens \verb|"w"|
(word) and \verb|"c"| (control sequence), each of the bold face
tokens in the grammar is represented by its respective character.
\begin{chunk}{*}
function getsym() {
  symvalue = ""
  # The following while loop skips white space and LaTeX comments
  while (ch == " " || ch == "%") {
     if (ch == "%") {while (ch != "\n") {nextCharacter()}}
     nextCharacter()
  }
  # Now test for all the tokens.
  if (index(",={}[]", ch)) {sym = ch; nextCharacter()}
  else if (ch == "\\") {
    nextCharacter()
    symvalue = ch
    if (index(letter, ch)) {
      sym = "c"
      nextCharacter()
      while (index(letter,ch)) {symvalue = symvalue ch; nextCharacter()}
    } else {
      sym = "w"
      nextCharacter()
      while (index(nonwordchar, ch) == 0) {
        symvalue = symvalue ch; nextCharacter()
      }
    }
  } else {
    sym = "w"
    symvalue = ch
    nextCharacter()
    while (index(nonwordchar, ch) == 0) {
      symvalue = symvalue ch; nextCharacter()
    }
  }
}
\end{chunk}

\subsubsection{The Parser}

The parser is a simple translation of the grammar from
page~\pageref{grammar} in the spirit of \cite[pp.~9--20]{Wirth:2005}.

The function \texttt{parseoptions} is the top-level parse function. It
assumes that the variable \texttt{lineidx} gives the index into the
current line after which parsing should start. The function returns
the token (which in our case should only be \verb|"]"| or \verb|"}"|)
of the text following the optional key/value pairs.
\begin{chunk}{*}
function parseoptions() {
  nextCharacter() # ch = look-ahead character
  getsym() # sym = look-ahead token
  goptions() # start parsing
  return sym
}
\end{chunk}

The following functions (all starting with the letter g for grammar)
form a direct translation of the grammar as given on
page~\pageref{grammar} into parsing functions.
\begin{chunk}{*}
function goptions() {
  gkeyval()
  while (sym == ",") {getsym(); gkeyval()}
}
\end{chunk}

Except for recognizing the grammar, the functions keep track of the
value of a key/value pair. This value is accumulated into the variable
\texttt{kvalue} and eventually stored into the \texttt{options} array
at the position given by the name of the key.
\begin{chunk}{*}
function gkeyval( keyname) {
  if (sym == "w") {
    keyname = symvalue
    getsym()
    kvalue = ""
    if (sym == "=") {getsym(); if (index("wc{[", sym)) {gvalue()}}
    options[keyname] = kvalue
  }
}
\end{chunk}
\begin{chunk}{*}
function gvalue() {while (index("wc{[", sym)) {gbalanced()}}
\end{chunk}
\begin{chunk}{*}
function gbalanced() {
  if (sym == "[") {
    kvalue = kvalue sym; getsym(); gbalancedx()
    if (sym == "]") {kvalue = kvalue sym; getsym()}
    else {error("Expected ']'")}
  } else gbalancedx()
}
\end{chunk}
\begin{chunk}{*}
function gbalancedx() {
  while (index("wc{", sym)) {
    if      (sym == "w") {kvalue = kvalue symvalue; getsym()}
    else if (sym == "c") {kvalue = kvalue "\\" symvalue; getsym()}
    else { # sym == "{"
      kvalue = kvalue sym; getsym(); gbalancedz()
      if (sym == "}") {kvalue = kvalue sym; getsym()}
      else {error("Expected '}'")}
    }
  }
}
\end{chunk}
\begin{chunk}{*}
function gbalancedz() {
  while (index(",=[]wc{", sym)) {
    if (index(",=[]", sym)) {kvalue = kvalue sym; getsym()}
    else gbalancedx()
  }
}
\end{chunk}


\subsubsection{Setting chunkref Delimiters}

The function \texttt{setchunkref} assumes that the global variable
\texttt{options} is an array that may or may not have an entry at the
index \texttt{chunkref}. If it has, then upon return the variables
\texttt{bdelim} and \texttt{edelim} will represent the respective
chunkref delimiters and 1 is returned. Otherwise \texttt{bdelim} and
\texttt{edelim} will be set to the global values \texttt{bdelimglobal}
and \texttt{edelimglobal} and 0 is returned.

We assume that \verb'options["chunkref"]' has a format like
\verb"{bdelim}{edelim}", so we split and remove the braces.
\begin{chunk}{*}
function setchunkref( idx, val) {
  if ("chunkref" in options) {
    val = options["chunkref"]
    idx = index(val, "}{")
    if (idx == 0) {
      error("chunkref value not givein in the form {bdelim}{edelim}")
    }
    bdelim = substr(val, 2, idx-2)
    edelim = substr(val, idx+2, length(val)-idx-2)
    return 1
  } else {
    bdelim = bdelimglobal
    edelim = edelimglobal
    retun 0
  }
}
\end{chunk}



\bibliographystyle{alpha}
\bibliography{prolitex}

\end{document}
% The following command can be used to generate the .awk file from
% this literate document. Just say
%   sh prolitex.awk.tex
% on the command line.
%%%%% BUILD-SCRIPT
awk '/^\\begin{chunk}/{c=1;next};/^\\end{chunk}/{c=0;next};c' <$0 >`echo $0|sed 's/\.tex$//'`
